{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c64fc123",
   "metadata": {},
   "source": [
    "# Document Classifier Training Notebook (Updated)\n",
    "\n",
    "This notebook trains a robust document classifier with:\n",
    "- Better handling of small datasets\n",
    "- Improved text preprocessing\n",
    "- Enhanced evaluation metrics\n",
    "- Model persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0b6c044",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\use\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b69e4bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading stopwords...\n",
      "Downloading wordnet...\n",
      "Downloading omw-1.4...\n",
      "Downloading averaged_perceptron_tagger...\n",
      "Setting up document classifier...\n",
      "\n",
      "Class distribution:\n",
      "label\n",
      "invoice     6\n",
      "resume      6\n",
      "id          6\n",
      "contract    4\n",
      "report      4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Preprocessing text...\n",
      "\n",
      "Sample before and after cleaning:\n",
      "Original: Invoice No: INV-12345\n",
      "Date: 2023-01-15\n",
      "To: ABC Company\n",
      "Description: Web Development Services\n",
      "Total:  ...\n",
      "Cleaned: invoice inv number date number number number abc company description web development service total c ...\n",
      "\n",
      "Creating feature vectors...\n",
      "\n",
      "Feature matrix shape: (26, 736)\n",
      "Top 10 features: ['abc' 'abc company' 'abc company description' 'abc corp'\n",
      " 'abc corp client' 'abc corp number' 'agreement' 'agreement agreement'\n",
      " 'agreement agreement entered' 'agreement agreement january']\n",
      "\n",
      "Training classifier...\n",
      "\n",
      "Cross-validation results:\n",
      "Fold 1 accuracy: 0.833\n",
      "Fold 2 accuracy: 0.600\n",
      "Fold 3 accuracy: 0.600\n",
      "Fold 4 accuracy: 0.800\n",
      "Fold 5 accuracy: 0.600\n",
      "Mean CV accuracy: 0.687 (+/- 0.213)\n",
      "\n",
      "==================================================\n",
      "FINAL MODEL EVALUATION\n",
      "==================================================\n",
      "\n",
      "Test Accuracy: 0.500\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    contract       0.00      0.00      0.00         1\n",
      "          id       0.00      0.00      0.00         1\n",
      "     invoice       0.50      1.00      0.67         1\n",
      "      report       0.00      0.00      0.00         1\n",
      "      resume       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.50         6\n",
      "   macro avg       0.23      0.40      0.29         6\n",
      "weighted avg       0.31      0.50      0.38         6\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0 0 1 0 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 1 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 0 0 2]]\n",
      "\n",
      "==================================================\n",
      "TOP FEATURES BY CLASS\n",
      "==================================================\n",
      "\n",
      "Top features for 'contract':\n",
      "  agreement: 0.527\n",
      "  lease: 0.373\n",
      "  entered: 0.307\n",
      "  lease agreement lease: 0.301\n",
      "  lease agreement: 0.301\n",
      "  agreement lease: 0.301\n",
      "  party: 0.284\n",
      "  software developer start: 0.236\n",
      "  employee position software: 0.236\n",
      "  company employee position: 0.236\n",
      "\n",
      "Top features for 'id':\n",
      "  passport: 0.384\n",
      "  state: 0.362\n",
      "  number number: 0.293\n",
      "  valid number: 0.282\n",
      "  valid number number: 0.282\n",
      "  valid: 0.282\n",
      "  number number number: 0.263\n",
      "  university: 0.235\n",
      "  birth number number: 0.227\n",
      "  date birth number: 0.227\n",
      "\n",
      "Top features for 'invoice':\n",
      "  invoice: 0.522\n",
      "  number date number: 0.364\n",
      "  number date: 0.364\n",
      "  currency: 0.363\n",
      "  invoice number: 0.308\n",
      "  currency number: 0.295\n",
      "  currency number number: 0.295\n",
      "  total: 0.265\n",
      "  invoice number number: 0.230\n",
      "  date number: 0.229\n",
      "\n",
      "Top features for 'report':\n",
      "  report: 0.383\n",
      "  status: 0.287\n",
      "  market: 0.267\n",
      "  january: 0.256\n",
      "  january number: 0.256\n",
      "  period: 0.186\n",
      "  period january: 0.186\n",
      "  period january number: 0.186\n",
      "  prepared shareholder: 0.186\n",
      "  number december: 0.186\n",
      "\n",
      "Top features for 'resume':\n",
      "  experience: 0.247\n",
      "  data: 0.238\n",
      "  skill: 0.238\n",
      "  python: 0.237\n",
      "  email: 0.226\n",
      "  project: 0.169\n",
      "  john doe: 0.163\n",
      "  doe: 0.163\n",
      "  analysis team leadership: 0.150\n",
      "  analysis team: 0.150\n",
      "\n",
      "==================================================\n",
      "SAVING MODEL\n",
      "==================================================\n",
      "Model and vectorizer saved to 'models/' directory\n",
      "\n",
      "==================================================\n",
      "TESTING CLASSIFICATION FUNCTION\n",
      "==================================================\n",
      "\n",
      "Test Document 1:\n",
      "Text: Invoice #12345 from ABC Corp for $500.00 due on March 15, 20...\n",
      "Prediction: invoice\n",
      "Confidence scores:\n",
      "  contract: -0.714\n",
      "  id: -0.714\n",
      "  invoice: -0.206\n",
      "  report: -0.597\n",
      "  resume: -0.672\n",
      "\n",
      "Test Document 2:\n",
      "Text: John Smith, Software Engineer with 5 years experience in Pyt...\n",
      "Prediction: resume\n",
      "Confidence scores:\n",
      "  contract: -0.651\n",
      "  id: -0.601\n",
      "  invoice: -0.704\n",
      "  report: -0.711\n",
      "  resume: -0.136\n",
      "\n",
      "Test Document 3:\n",
      "Text: Driver License ID: DL123456, John Doe, DOB: 01/01/1990...\n",
      "Prediction: id\n",
      "Confidence scores:\n",
      "  contract: -0.813\n",
      "  id: 0.006\n",
      "  invoice: -0.726\n",
      "  report: -0.804\n",
      "  resume: -0.616\n",
      "\n",
      "Test Document 4:\n",
      "Text: This agreement is between Company A and Company B for softwa...\n",
      "Prediction: contract\n",
      "Confidence scores:\n",
      "  contract: -0.289\n",
      "  id: -0.739\n",
      "  invoice: -0.481\n",
      "  report: -0.668\n",
      "  resume: -0.580\n",
      "\n",
      "Test Document 5:\n",
      "Text: Quarterly sales report showing 15% growth in Q1 2023...\n",
      "Prediction: id\n",
      "Confidence scores:\n",
      "  contract: -0.809\n",
      "  id: -0.374\n",
      "  invoice: -0.519\n",
      "  report: -0.415\n",
      "  resume: -0.870\n",
      "\n",
      "==================================================\n",
      "TRAINING COMPLETE!\n",
      "==================================================\n",
      "Files saved:\n",
      "- models/vectorizer.pkl\n",
      "- models/classifier.pkl\n",
      "\n",
      "Use classify_document() function to classify new documents.\n"
     ]
    }
   ],
   "source": [
    "# Document Classifier Training Script (Fixed)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import joblib\n",
    "import os\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download NLTK resources with proper error handling\n",
    "def download_nltk_data():\n",
    "    \"\"\"Download required NLTK data with error handling\"\"\"\n",
    "    required_packages = ['punkt', 'stopwords', 'wordnet', 'omw-1.4', 'averaged_perceptron_tagger']\n",
    "    \n",
    "    for package in required_packages:\n",
    "        try:\n",
    "            nltk.data.find(f'tokenizers/{package}')\n",
    "        except LookupError:\n",
    "            print(f\"Downloading {package}...\")\n",
    "            nltk.download(package, quiet=True)\n",
    "        except:\n",
    "            try:\n",
    "                nltk.data.find(f'corpora/{package}')\n",
    "            except LookupError:\n",
    "                print(f\"Downloading {package}...\")\n",
    "                nltk.download(package, quiet=True)\n",
    "            except:\n",
    "                try:\n",
    "                    nltk.data.find(f'taggers/{package}')\n",
    "                except LookupError:\n",
    "                    print(f\"Downloading {package}...\")\n",
    "                    nltk.download(package, quiet=True)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "# Initialize NLTK\n",
    "download_nltk_data()\n",
    "\n",
    "print(\"Setting up document classifier...\")\n",
    "\n",
    "# Enhanced training data with realistic examples\n",
    "data = [\n",
    "    # Invoices\n",
    "    (\"invoice\", \"Invoice No: INV-12345\\nDate: 2023-01-15\\nTo: ABC Company\\nDescription: Web Development Services\\nTotal: $1,200.00\"),\n",
    "    (\"invoice\", \"TAX INVOICE\\nNumber: 98765\\nIssued: 15/01/2023\\nClient: XYZ Corp\\nAmount Due: $850.00\\nPayment Due: 30 days\"),\n",
    "    (\"invoice\", \"INVOICE\\nFrom: Smith Services\\nTo: Johnson Ltd\\nDate: January 15, 2023\\nSubtotal: $750.00\\nTax: $75.00\\nTotal: $825.00\"),\n",
    "    (\"invoice\", \"SERVICE INVOICE\\nInvoice #: 45678\\nDate: 2023-02-01\\nCustomer: Global Tech\\nDescription: Monthly Maintenance\\nTotal: $500.00\"),\n",
    "    (\"invoice\", \"PRO FORMA INVOICE\\nRef: PF-2023-03\\nDate: 01-Mar-2023\\nBill To: Continental Ltd\\nAmount: $1,450.00\"),\n",
    "    (\"invoice\", \"COMMERCIAL INVOICE\\nInvoice Number: CI-78901\\nDate: 15-Mar-2023\\nShip To: Oceanic Trading\\nTotal Value: $2,300.00\"),\n",
    "    \n",
    "    # Resumes\n",
    "    (\"resume\", \"JOHN DOE\\n123 Main St, City\\nPhone: (123) 456-7890\\nEmail: john.doe@email.com\\n\\nEXPERIENCE\\nSenior Developer, ABC Corp (2020-Present)\"),\n",
    "    (\"resume\", \"JANE SMITH - CURRICULUM VITAE\\nEducation: Master of Computer Science, University X\\nSkills: Python, Java, SQL, Machine Learning\"),\n",
    "    (\"resume\", \"RESUME\\nMICHAEL BROWN\\nObjective: Seeking software engineering position\\nProjects: Built document classification system using Python\"),\n",
    "    (\"resume\", \"ALICE JOHNSON\\nPROFESSIONAL SUMMARY\\nData Scientist with 5+ years experience\\nTechnical Skills: Python, R, TensorFlow, PyTorch\"),\n",
    "    (\"resume\", \"DAVID WILSON - CV\\nWORK HISTORY\\nSenior Analyst, Data Insights Co. (2018-2023)\\nEDUCATION\\nPhD in Computer Science\"),\n",
    "    (\"resume\", \"SARAH MILLER\\nSKILLS\\nProject Management\\nData Analysis\\nTeam Leadership\\nCERTIFICATIONS\\nPMP, AWS Certified\"),\n",
    "    \n",
    "    # ID Documents\n",
    "    (\"id\", \"UNITED STATES PASSPORT\\nPassport No: 123456789\\nName: JOHN DOE\\nDate of Birth: 01/01/1980\\nExpiry Date: 01/01/2030\"),\n",
    "    (\"id\", \"DRIVER LICENSE\\nState: California\\nDL Number: B1234567\\nName: JANE SMITH\\nDOB: 05/15/1985\"),\n",
    "    (\"id\", \"NATIONAL ID CARD\\nID Number: 987654321\\nName: ROBERT JOHNSON\\nIssued: 2020-01-01\\nValid Until: 2030-01-01\"),\n",
    "    (\"id\", \"UNITED KINGDOM PASSPORT\\nPassport No: GB12345678\\nSurname: WILLIAMS\\nGiven Names: EMILY\\nDate of Birth: 12/08/1990\"),\n",
    "    (\"id\", \"EMPLOYEE ID CARD\\nCompany: Tech Solutions Inc.\\nID: TS-789456\\nName: MICHAEL CHEN\\nDepartment: Engineering\"),\n",
    "    (\"id\", \"STUDENT ID\\nUniversity: State University\\nID: SU-2023-456\\nName: JESSICA TAYLOR\\nValid Thru: 06/2025\"),\n",
    "    \n",
    "    # Contracts\n",
    "    (\"contract\", \"SERVICE AGREEMENT\\nThis Agreement is made on January 15, 2023 between ABC Corp (Client) and XYZ Services (Provider).\"),\n",
    "    (\"contract\", \"EMPLOYMENT CONTRACT\\nBetween: Company Inc.\\nAnd: Employee Name\\nPosition: Software Developer\\nStart Date: 01/02/2023\"),\n",
    "    (\"contract\", \"CONFIDENTIALITY AGREEMENT\\nThis Nondisclosure Agreement (the 'Agreement') is entered into by and between\\nDisclosing Party: Innovate Tech\\nReceiving Party: Consultant\"),\n",
    "    (\"contract\", \"LEASE AGREEMENT\\nThis Lease Agreement ('Lease') is made and entered into this 1st day of March, 2023\\nBetween: Landlord\\nAnd: Tenant\"),\n",
    "    \n",
    "    # Reports\n",
    "    (\"report\", \"ANNUAL FINANCIAL REPORT 2022\\nPrepared for: Shareholders\\nPeriod: January 1 - December 31, 2022\\nRevenue: $10M\"),\n",
    "    (\"report\", \"MARKET ANALYSIS REPORT\\nIndustry: Technology\\nAuthor: Analytics Team\\nDate: January 2023\\nKey Findings: Market growing at 5% annually\"),\n",
    "    (\"report\", \"PROJECT STATUS REPORT\\nProject: Document Classification System\\nDate: March 15, 2023\\nStatus: Development Phase 2\\nNext Steps: Model Optimization\"),\n",
    "    (\"report\", \"MEDICAL LAB REPORT\\nPatient: John Smith\\nDate: 02/28/2023\\nTest: Complete Blood Count\\nResults: Within normal limits\")\n",
    "]\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data, columns=['label', 'text'])\n",
    "print(\"\\nClass distribution:\")\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Enhanced text preprocessing with fallback for POS tagging\"\"\"\n",
    "    try:\n",
    "        # Remove HTML tags\n",
    "        text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "        \n",
    "        # Replace currency and numbers with tokens\n",
    "        text = re.sub(r'\\$\\d+\\.?\\d*', '[CURRENCY]', text)\n",
    "        text = re.sub(r'\\d+', '[NUMBER]', text)\n",
    "        \n",
    "        # Clean special characters but keep important punctuation\n",
    "        text = re.sub(r'[^\\w\\s.,;:!?\\'\"-]', ' ', text)\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Tokenize\n",
    "        words = re.findall(r'\\b[\\w-]+\\b', text)\n",
    "        \n",
    "        # Remove stopwords (keep some negations)\n",
    "        try:\n",
    "            stop_words = set(stopwords.words('english')) - {'not', 'no', 'nor'}\n",
    "        except:\n",
    "            # Fallback if stopwords not available\n",
    "            stop_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by'}\n",
    "        \n",
    "        words = [word for word in words if word not in stop_words and len(word) > 2]\n",
    "        \n",
    "        # Lemmatization with POS tagging fallback\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        try:\n",
    "            # Try POS tagging\n",
    "            pos_tags = nltk.pos_tag(words)\n",
    "            words = [\n",
    "                lemmatizer.lemmatize(word, 'v' if tag.startswith('V') else 'n')\n",
    "                for word, tag in pos_tags\n",
    "            ]\n",
    "        except:\n",
    "            # Fallback: simple lemmatization without POS\n",
    "            words = [lemmatizer.lemmatize(word) for word in words]\n",
    "        \n",
    "        return ' '.join(words)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in preprocessing: {e}\")\n",
    "        # Minimal preprocessing fallback\n",
    "        text = re.sub(r'[^\\w\\s]', ' ', text.lower())\n",
    "        words = text.split()\n",
    "        return ' '.join([word for word in words if len(word) > 2])\n",
    "\n",
    "# Apply preprocessing\n",
    "print(\"\\nPreprocessing text...\")\n",
    "df['cleaned_text'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "print(\"\\nSample before and after cleaning:\")\n",
    "print(\"Original:\", df['text'][0][:100], \"...\")\n",
    "print(\"Cleaned:\", df['cleaned_text'][0][:100], \"...\")\n",
    "\n",
    "# Smart Text Vectorization\n",
    "print(\"\\nCreating feature vectors...\")\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=3000,\n",
    "    ngram_range=(1, 3),\n",
    "    min_df=1,  # Reduced for small dataset\n",
    "    max_df=0.9,\n",
    "    stop_words='english',\n",
    "    sublinear_tf=True,\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\b[\\w-]+\\b'\n",
    ")\n",
    "\n",
    "X = vectorizer.fit_transform(df['cleaned_text'])\n",
    "y = df['label']\n",
    "\n",
    "print(f\"\\nFeature matrix shape: {X.shape}\")\n",
    "print(\"Top 10 features:\", vectorizer.get_feature_names_out()[:10])\n",
    "\n",
    "# Model Training with Cross-Validation\n",
    "print(\"\\nTraining classifier...\")\n",
    "classifier = LinearSVC(\n",
    "    C=0.8,\n",
    "    class_weight='balanced',\n",
    "    max_iter=20000,\n",
    "    random_state=42,\n",
    "    dual=False\n",
    ")\n",
    "\n",
    "# Cross-validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(classifier, X, y, cv=skf, scoring='accuracy')\n",
    "\n",
    "print(f\"\\nCross-validation results:\")\n",
    "for i, score in enumerate(cv_scores):\n",
    "    print(f\"Fold {i+1} accuracy: {score:.3f}\")\n",
    "print(f\"Mean CV accuracy: {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})\")\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Final model training\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL MODEL EVALUATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"\\nTest Accuracy: {accuracy_score(y_test, y_pred):.3f}\")\n",
    "\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "# Feature importance analysis\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TOP FEATURES BY CLASS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "classes = classifier.classes_\n",
    "\n",
    "for i, class_name in enumerate(classes):\n",
    "    print(f\"\\nTop features for '{class_name}':\")\n",
    "    # Get coefficients for this class\n",
    "    if len(classes) == 2:\n",
    "        coef = classifier.coef_[0] if i == 1 else -classifier.coef_[0]\n",
    "    else:\n",
    "        coef = classifier.coef_[i]\n",
    "    \n",
    "    # Get top features\n",
    "    top_indices = coef.argsort()[-10:][::-1]\n",
    "    top_features = [(feature_names[idx], coef[idx]) for idx in top_indices]\n",
    "    \n",
    "    for feature, score in top_features:\n",
    "        print(f\"  {feature}: {score:.3f}\")\n",
    "\n",
    "# Save the model and vectorizer\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SAVING MODEL\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Save vectorizer and classifier\n",
    "joblib.dump(vectorizer, 'models/vectorizer.pkl')\n",
    "joblib.dump(classifier, 'models/classifier.pkl')\n",
    "\n",
    "print(\"Model and vectorizer saved to 'models/' directory\")\n",
    "\n",
    "# Function to classify new documents\n",
    "def classify_document(text, vectorizer_path='models/vectorizer.pkl', classifier_path='models/classifier.pkl'):\n",
    "    \"\"\"\n",
    "    Classify a new document\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load models\n",
    "        vectorizer = joblib.load(vectorizer_path)\n",
    "        classifier = joblib.load(classifier_path)\n",
    "        \n",
    "        # Preprocess text\n",
    "        cleaned_text = preprocess_text(text)\n",
    "        \n",
    "        # Vectorize\n",
    "        text_vector = vectorizer.transform([cleaned_text])\n",
    "        \n",
    "        # Predict\n",
    "        prediction = classifier.predict(text_vector)[0]\n",
    "        probabilities = classifier.decision_function(text_vector)[0]\n",
    "        \n",
    "        # Get confidence scores\n",
    "        confidence_scores = {}\n",
    "        for i, class_name in enumerate(classifier.classes_):\n",
    "            if len(classifier.classes_) == 2:\n",
    "                # Binary classification\n",
    "                conf = probabilities if i == 1 else -probabilities\n",
    "            else:\n",
    "                # Multi-class classification\n",
    "                conf = probabilities[i]\n",
    "            confidence_scores[class_name] = conf\n",
    "        \n",
    "        return {\n",
    "            'prediction': prediction,\n",
    "            'confidence_scores': confidence_scores,\n",
    "            'preprocessed_text': cleaned_text\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {'error': str(e)}\n",
    "\n",
    "# Test the classification function\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TESTING CLASSIFICATION FUNCTION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "test_documents = [\n",
    "    \"Invoice #12345 from ABC Corp for $500.00 due on March 15, 2023\",\n",
    "    \"John Smith, Software Engineer with 5 years experience in Python and Java\",\n",
    "    \"Driver License ID: DL123456, John Doe, DOB: 01/01/1990\",\n",
    "    \"This agreement is between Company A and Company B for software development services\",\n",
    "    \"Quarterly sales report showing 15% growth in Q1 2023\"\n",
    "]\n",
    "\n",
    "for i, doc in enumerate(test_documents):\n",
    "    result = classify_document(doc)\n",
    "    if 'error' not in result:\n",
    "        print(f\"\\nTest Document {i+1}:\")\n",
    "        print(f\"Text: {doc[:60]}...\")\n",
    "        print(f\"Prediction: {result['prediction']}\")\n",
    "        print(\"Confidence scores:\")\n",
    "        for class_name, score in result['confidence_scores'].items():\n",
    "            print(f\"  {class_name}: {score:.3f}\")\n",
    "    else:\n",
    "        print(f\"Error classifying document {i+1}: {result['error']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TRAINING COMPLETE!\")\n",
    "print(\"=\"*50)\n",
    "print(\"Files saved:\")\n",
    "print(\"- models/vectorizer.pkl\")\n",
    "print(\"- models/classifier.pkl\")\n",
    "print(\"\\nUse classify_document() function to classify new documents.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ducument_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
